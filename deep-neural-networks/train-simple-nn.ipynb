{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images('animals')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, resize the image to be 32x32 pixels (ignoring\n",
    "    # aspect ratio), flatten the image into 32x32x3=3072 pixel image\n",
    "    # into a list, and store the image in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (32, 32)).flatten()\n",
    "    data.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors (for 2-class, binary\n",
    "# classification you should use Keras' to_categorical function\n",
    "# instead as the scikit-learn's LabelBinarizer will not return a\n",
    "# vector)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the 3072-1024-512-3 architecture using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate and # of epochs to train for\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 150\n",
    "\n",
    "# compile the model using SGD as our optimizer and categorical\n",
    "# cross-entropy loss (you'll want to use binary_crossentropy\n",
    "# for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cats', 'dogs', 'panda'], dtype='<U5')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2250 samples, validate on 750 samples\n",
      "Epoch 1/150\n",
      "2250/2250 [==============================] - 2s 847us/step - loss: 1.1016 - accuracy: 0.3444 - val_loss: 1.0954 - val_accuracy: 0.3147\n",
      "Epoch 2/150\n",
      "2250/2250 [==============================] - 2s 801us/step - loss: 1.0853 - accuracy: 0.3898 - val_loss: 1.0874 - val_accuracy: 0.3160\n",
      "Epoch 3/150\n",
      "2250/2250 [==============================] - 2s 819us/step - loss: 1.0697 - accuracy: 0.4089 - val_loss: 1.0464 - val_accuracy: 0.4987\n",
      "Epoch 4/150\n",
      "2250/2250 [==============================] - 2s 802us/step - loss: 1.0496 - accuracy: 0.4596 - val_loss: 1.0724 - val_accuracy: 0.3280\n",
      "Epoch 5/150\n",
      "2250/2250 [==============================] - 2s 789us/step - loss: 1.0410 - accuracy: 0.4498 - val_loss: 1.0397 - val_accuracy: 0.5040\n",
      "Epoch 6/150\n",
      "2250/2250 [==============================] - 2s 808us/step - loss: 1.0219 - accuracy: 0.4876 - val_loss: 1.0240 - val_accuracy: 0.4733\n",
      "Epoch 7/150\n",
      "2250/2250 [==============================] - 2s 807us/step - loss: 1.0027 - accuracy: 0.5093 - val_loss: 0.9871 - val_accuracy: 0.5280\n",
      "Epoch 8/150\n",
      "2250/2250 [==============================] - 2s 795us/step - loss: 0.9952 - accuracy: 0.4964 - val_loss: 0.9809 - val_accuracy: 0.5093\n",
      "Epoch 9/150\n",
      "2250/2250 [==============================] - 2s 801us/step - loss: 0.9758 - accuracy: 0.5067 - val_loss: 0.9602 - val_accuracy: 0.5347\n",
      "Epoch 10/150\n",
      "2250/2250 [==============================] - 2s 798us/step - loss: 0.9676 - accuracy: 0.5120 - val_loss: 0.9500 - val_accuracy: 0.5387\n",
      "Epoch 11/150\n",
      "2250/2250 [==============================] - 2s 796us/step - loss: 0.9514 - accuracy: 0.5227 - val_loss: 0.9304 - val_accuracy: 0.5253\n",
      "Epoch 12/150\n",
      "2250/2250 [==============================] - 2s 835us/step - loss: 0.9405 - accuracy: 0.5218 - val_loss: 0.9356 - val_accuracy: 0.5307\n",
      "Epoch 13/150\n",
      "2250/2250 [==============================] - 2s 803us/step - loss: 0.9250 - accuracy: 0.5373 - val_loss: 0.9102 - val_accuracy: 0.5493\n",
      "Epoch 14/150\n",
      "2250/2250 [==============================] - 2s 811us/step - loss: 0.9187 - accuracy: 0.5347 - val_loss: 0.9558 - val_accuracy: 0.4987\n",
      "Epoch 15/150\n",
      "2250/2250 [==============================] - 2s 803us/step - loss: 0.9118 - accuracy: 0.5422 - val_loss: 0.8956 - val_accuracy: 0.5640\n",
      "Epoch 16/150\n",
      "2250/2250 [==============================] - 2s 697us/step - loss: 0.9027 - accuracy: 0.5244 - val_loss: 0.9111 - val_accuracy: 0.5320\n",
      "Epoch 17/150\n",
      "2250/2250 [==============================] - 2s 690us/step - loss: 0.8971 - accuracy: 0.5502 - val_loss: 0.8787 - val_accuracy: 0.5933\n",
      "Epoch 18/150\n",
      "2250/2250 [==============================] - 2s 761us/step - loss: 0.8913 - accuracy: 0.5418 - val_loss: 0.8882 - val_accuracy: 0.5560\n",
      "Epoch 19/150\n",
      "2250/2250 [==============================] - 2s 818us/step - loss: 0.8842 - accuracy: 0.5458 - val_loss: 0.9299 - val_accuracy: 0.5187\n",
      "Epoch 20/150\n",
      "2250/2250 [==============================] - 2s 815us/step - loss: 0.8777 - accuracy: 0.5427 - val_loss: 0.8997 - val_accuracy: 0.5507\n",
      "Epoch 21/150\n",
      "2250/2250 [==============================] - 2s 810us/step - loss: 0.8776 - accuracy: 0.5462 - val_loss: 0.8787 - val_accuracy: 0.5360\n",
      "Epoch 22/150\n",
      "2250/2250 [==============================] - 2s 828us/step - loss: 0.8700 - accuracy: 0.5578 - val_loss: 0.8583 - val_accuracy: 0.5907\n",
      "Epoch 23/150\n",
      "2250/2250 [==============================] - 2s 846us/step - loss: 0.8681 - accuracy: 0.5538 - val_loss: 0.8788 - val_accuracy: 0.5267\n",
      "Epoch 24/150\n",
      "2250/2250 [==============================] - 2s 821us/step - loss: 0.8643 - accuracy: 0.5498 - val_loss: 0.8708 - val_accuracy: 0.5227\n",
      "Epoch 25/150\n",
      "2250/2250 [==============================] - 2s 812us/step - loss: 0.8598 - accuracy: 0.5516 - val_loss: 0.8484 - val_accuracy: 0.6000\n",
      "Epoch 26/150\n",
      "2250/2250 [==============================] - 2s 810us/step - loss: 0.8573 - accuracy: 0.5658 - val_loss: 0.8708 - val_accuracy: 0.5440\n",
      "Epoch 27/150\n",
      "2250/2250 [==============================] - 2s 798us/step - loss: 0.8610 - accuracy: 0.5431 - val_loss: 0.9318 - val_accuracy: 0.5013\n",
      "Epoch 28/150\n",
      "2250/2250 [==============================] - 2s 802us/step - loss: 0.8535 - accuracy: 0.5644 - val_loss: 0.8708 - val_accuracy: 0.5693\n",
      "Epoch 29/150\n",
      "2250/2250 [==============================] - 2s 807us/step - loss: 0.8453 - accuracy: 0.5591 - val_loss: 0.9104 - val_accuracy: 0.5253\n",
      "Epoch 30/150\n",
      "2250/2250 [==============================] - 2s 866us/step - loss: 0.8429 - accuracy: 0.5742 - val_loss: 0.8637 - val_accuracy: 0.5533\n",
      "Epoch 31/150\n",
      "2250/2250 [==============================] - 2s 811us/step - loss: 0.8390 - accuracy: 0.5738 - val_loss: 0.9470 - val_accuracy: 0.5013\n",
      "Epoch 32/150\n",
      "2250/2250 [==============================] - 2s 806us/step - loss: 0.8391 - accuracy: 0.5769 - val_loss: 0.8343 - val_accuracy: 0.5920\n",
      "Epoch 33/150\n",
      "2250/2250 [==============================] - 2s 862us/step - loss: 0.8358 - accuracy: 0.5711 - val_loss: 0.8354 - val_accuracy: 0.5867\n",
      "Epoch 34/150\n",
      "2250/2250 [==============================] - 2s 852us/step - loss: 0.8336 - accuracy: 0.5627 - val_loss: 0.8371 - val_accuracy: 0.5813\n",
      "Epoch 35/150\n",
      "2250/2250 [==============================] - 2s 812us/step - loss: 0.8281 - accuracy: 0.5751 - val_loss: 0.8431 - val_accuracy: 0.6013\n",
      "Epoch 36/150\n",
      "2250/2250 [==============================] - 2s 839us/step - loss: 0.8278 - accuracy: 0.5791 - val_loss: 0.8405 - val_accuracy: 0.5640\n",
      "Epoch 37/150\n",
      "2250/2250 [==============================] - 2s 825us/step - loss: 0.8280 - accuracy: 0.5622 - val_loss: 0.8326 - val_accuracy: 0.5960\n",
      "Epoch 38/150\n",
      "2250/2250 [==============================] - 2s 855us/step - loss: 0.8288 - accuracy: 0.5689 - val_loss: 0.8377 - val_accuracy: 0.5693\n",
      "Epoch 39/150\n",
      "2250/2250 [==============================] - 2s 816us/step - loss: 0.8260 - accuracy: 0.5693 - val_loss: 0.8302 - val_accuracy: 0.6053\n",
      "Epoch 40/150\n",
      "2250/2250 [==============================] - 2s 802us/step - loss: 0.8227 - accuracy: 0.5831 - val_loss: 0.8596 - val_accuracy: 0.5840\n",
      "Epoch 41/150\n",
      "2250/2250 [==============================] - 2s 797us/step - loss: 0.8218 - accuracy: 0.5800 - val_loss: 0.8337 - val_accuracy: 0.5867\n",
      "Epoch 42/150\n",
      "2250/2250 [==============================] - 2s 803us/step - loss: 0.8198 - accuracy: 0.5880 - val_loss: 0.8441 - val_accuracy: 0.5933\n",
      "Epoch 43/150\n",
      "2250/2250 [==============================] - 2s 835us/step - loss: 0.8158 - accuracy: 0.5831 - val_loss: 0.8255 - val_accuracy: 0.6093\n",
      "Epoch 44/150\n",
      "2250/2250 [==============================] - 2s 849us/step - loss: 0.8159 - accuracy: 0.5733 - val_loss: 0.8347 - val_accuracy: 0.6040\n",
      "Epoch 45/150\n",
      "2250/2250 [==============================] - 2s 817us/step - loss: 0.8155 - accuracy: 0.5702 - val_loss: 0.8298 - val_accuracy: 0.5920\n",
      "Epoch 46/150\n",
      "2250/2250 [==============================] - 2s 811us/step - loss: 0.8171 - accuracy: 0.5711 - val_loss: 0.8545 - val_accuracy: 0.5467\n",
      "Epoch 47/150\n",
      "2250/2250 [==============================] - 2s 815us/step - loss: 0.8122 - accuracy: 0.5822 - val_loss: 0.8550 - val_accuracy: 0.5960\n",
      "Epoch 48/150\n",
      "2250/2250 [==============================] - 2s 815us/step - loss: 0.8112 - accuracy: 0.5720 - val_loss: 0.8243 - val_accuracy: 0.6107\n",
      "Epoch 49/150\n",
      "2250/2250 [==============================] - 2s 830us/step - loss: 0.8067 - accuracy: 0.5929 - val_loss: 0.8784 - val_accuracy: 0.5480\n",
      "Epoch 50/150\n",
      "2250/2250 [==============================] - 2s 817us/step - loss: 0.8050 - accuracy: 0.5982 - val_loss: 0.8288 - val_accuracy: 0.6133\n",
      "Epoch 51/150\n",
      "2250/2250 [==============================] - 2s 810us/step - loss: 0.8053 - accuracy: 0.5822 - val_loss: 0.8918 - val_accuracy: 0.5347\n",
      "Epoch 52/150\n",
      "2250/2250 [==============================] - 2s 829us/step - loss: 0.8038 - accuracy: 0.5929 - val_loss: 0.8419 - val_accuracy: 0.5867\n",
      "Epoch 53/150\n",
      "2250/2250 [==============================] - 2s 861us/step - loss: 0.8030 - accuracy: 0.5822 - val_loss: 0.8340 - val_accuracy: 0.5973\n",
      "Epoch 54/150\n",
      "2250/2250 [==============================] - 2s 833us/step - loss: 0.7987 - accuracy: 0.6027 - val_loss: 0.8202 - val_accuracy: 0.6107\n",
      "Epoch 55/150\n",
      "2250/2250 [==============================] - 2s 842us/step - loss: 0.7989 - accuracy: 0.5916 - val_loss: 0.8924 - val_accuracy: 0.5307\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 2s 829us/step - loss: 0.8016 - accuracy: 0.5956 - val_loss: 0.8278 - val_accuracy: 0.6080\n",
      "Epoch 57/150\n",
      "2250/2250 [==============================] - 2s 805us/step - loss: 0.7967 - accuracy: 0.6009 - val_loss: 0.8512 - val_accuracy: 0.5627\n",
      "Epoch 58/150\n",
      "2250/2250 [==============================] - 2s 805us/step - loss: 0.7955 - accuracy: 0.5942 - val_loss: 0.8415 - val_accuracy: 0.5573\n",
      "Epoch 59/150\n",
      "2250/2250 [==============================] - 2s 811us/step - loss: 0.7959 - accuracy: 0.5893 - val_loss: 0.8236 - val_accuracy: 0.6067\n",
      "Epoch 60/150\n",
      "2250/2250 [==============================] - 2s 818us/step - loss: 0.7923 - accuracy: 0.6058 - val_loss: 0.8447 - val_accuracy: 0.5813\n",
      "Epoch 61/150\n",
      "2250/2250 [==============================] - 2s 839us/step - loss: 0.7942 - accuracy: 0.6004 - val_loss: 0.9285 - val_accuracy: 0.5253\n",
      "Epoch 62/150\n",
      "2250/2250 [==============================] - 2s 814us/step - loss: 0.7935 - accuracy: 0.5907 - val_loss: 0.8359 - val_accuracy: 0.5800\n",
      "Epoch 63/150\n",
      "2250/2250 [==============================] - 2s 830us/step - loss: 0.7925 - accuracy: 0.6044 - val_loss: 0.8492 - val_accuracy: 0.6027\n",
      "Epoch 64/150\n",
      "2250/2250 [==============================] - 2s 837us/step - loss: 0.7888 - accuracy: 0.5876 - val_loss: 0.8612 - val_accuracy: 0.5533\n",
      "Epoch 65/150\n",
      "2250/2250 [==============================] - 2s 818us/step - loss: 0.7929 - accuracy: 0.5964 - val_loss: 0.8178 - val_accuracy: 0.5947\n",
      "Epoch 66/150\n",
      "2250/2250 [==============================] - 2s 811us/step - loss: 0.7860 - accuracy: 0.6040 - val_loss: 0.8580 - val_accuracy: 0.5667\n",
      "Epoch 67/150\n",
      "2250/2250 [==============================] - 2s 799us/step - loss: 0.7860 - accuracy: 0.6053 - val_loss: 0.8335 - val_accuracy: 0.5693\n",
      "Epoch 68/150\n",
      "2250/2250 [==============================] - 2s 798us/step - loss: 0.7841 - accuracy: 0.6053 - val_loss: 0.8788 - val_accuracy: 0.5427\n",
      "Epoch 69/150\n",
      "2250/2250 [==============================] - 2s 797us/step - loss: 0.7823 - accuracy: 0.6142 - val_loss: 0.8197 - val_accuracy: 0.6173\n",
      "Epoch 70/150\n",
      "2250/2250 [==============================] - 2s 813us/step - loss: 0.7776 - accuracy: 0.6062 - val_loss: 0.8174 - val_accuracy: 0.6093\n",
      "Epoch 71/150\n",
      "2250/2250 [==============================] - 2s 837us/step - loss: 0.7810 - accuracy: 0.6129 - val_loss: 0.8907 - val_accuracy: 0.5587\n",
      "Epoch 72/150\n",
      "2250/2250 [==============================] - 2s 821us/step - loss: 0.7822 - accuracy: 0.6062 - val_loss: 0.8241 - val_accuracy: 0.6107\n",
      "Epoch 73/150\n",
      "2250/2250 [==============================] - 2s 853us/step - loss: 0.7734 - accuracy: 0.6067 - val_loss: 0.8673 - val_accuracy: 0.6000\n",
      "Epoch 74/150\n",
      "2250/2250 [==============================] - 2s 803us/step - loss: 0.7741 - accuracy: 0.6187 - val_loss: 0.8242 - val_accuracy: 0.5800\n",
      "Epoch 75/150\n",
      "2250/2250 [==============================] - 2s 801us/step - loss: 0.7697 - accuracy: 0.6116 - val_loss: 0.8279 - val_accuracy: 0.5973\n",
      "Epoch 76/150\n",
      "2250/2250 [==============================] - 2s 802us/step - loss: 0.7790 - accuracy: 0.6111 - val_loss: 0.8142 - val_accuracy: 0.6173\n",
      "Epoch 77/150\n",
      "2250/2250 [==============================] - 2s 805us/step - loss: 0.7702 - accuracy: 0.6147 - val_loss: 0.8593 - val_accuracy: 0.5360\n",
      "Epoch 78/150\n",
      "2250/2250 [==============================] - 2s 803us/step - loss: 0.7698 - accuracy: 0.6160 - val_loss: 0.9318 - val_accuracy: 0.5093\n",
      "Epoch 79/150\n",
      "2250/2250 [==============================] - 2s 806us/step - loss: 0.7709 - accuracy: 0.6151 - val_loss: 0.8830 - val_accuracy: 0.5320\n",
      "Epoch 80/150\n",
      "2250/2250 [==============================] - 2s 799us/step - loss: 0.7698 - accuracy: 0.6089 - val_loss: 0.9179 - val_accuracy: 0.5267\n",
      "Epoch 81/150\n",
      "2250/2250 [==============================] - 2s 792us/step - loss: 0.7675 - accuracy: 0.6151 - val_loss: 0.8651 - val_accuracy: 0.5387\n",
      "Epoch 82/150\n",
      "2250/2250 [==============================] - 2s 794us/step - loss: 0.7618 - accuracy: 0.6249 - val_loss: 0.8218 - val_accuracy: 0.5920\n",
      "Epoch 83/150\n",
      "2250/2250 [==============================] - 2s 794us/step - loss: 0.7648 - accuracy: 0.6151 - val_loss: 0.8349 - val_accuracy: 0.5587\n",
      "Epoch 84/150\n",
      "2250/2250 [==============================] - 2s 801us/step - loss: 0.7645 - accuracy: 0.6173 - val_loss: 0.8551 - val_accuracy: 0.5680\n",
      "Epoch 85/150\n",
      "2250/2250 [==============================] - 2s 798us/step - loss: 0.7614 - accuracy: 0.6342 - val_loss: 0.8484 - val_accuracy: 0.6000\n",
      "Epoch 86/150\n",
      "2250/2250 [==============================] - 2s 798us/step - loss: 0.7618 - accuracy: 0.6302 - val_loss: 0.8162 - val_accuracy: 0.5920\n",
      "Epoch 87/150\n",
      "2250/2250 [==============================] - 2s 797us/step - loss: 0.7597 - accuracy: 0.6169 - val_loss: 0.8960 - val_accuracy: 0.5693\n",
      "Epoch 88/150\n",
      "2250/2250 [==============================] - 2s 796us/step - loss: 0.7582 - accuracy: 0.6213 - val_loss: 0.9055 - val_accuracy: 0.5253\n",
      "Epoch 89/150\n",
      "2250/2250 [==============================] - 2s 802us/step - loss: 0.7592 - accuracy: 0.6258 - val_loss: 0.8444 - val_accuracy: 0.5547\n",
      "Epoch 90/150\n",
      "2250/2250 [==============================] - 2s 798us/step - loss: 0.7567 - accuracy: 0.6267 - val_loss: 0.8208 - val_accuracy: 0.5920\n",
      "Epoch 91/150\n",
      "2250/2250 [==============================] - 2s 795us/step - loss: 0.7561 - accuracy: 0.6258 - val_loss: 0.8195 - val_accuracy: 0.6067\n",
      "Epoch 92/150\n",
      "2250/2250 [==============================] - 2s 799us/step - loss: 0.7521 - accuracy: 0.6333 - val_loss: 0.8385 - val_accuracy: 0.5773\n",
      "Epoch 93/150\n",
      "2250/2250 [==============================] - 2s 811us/step - loss: 0.7518 - accuracy: 0.6298 - val_loss: 0.8936 - val_accuracy: 0.5667\n",
      "Epoch 94/150\n",
      "2250/2250 [==============================] - 2s 870us/step - loss: 0.7517 - accuracy: 0.6338 - val_loss: 0.8453 - val_accuracy: 0.5787\n",
      "Epoch 95/150\n",
      "2250/2250 [==============================] - 2s 830us/step - loss: 0.7537 - accuracy: 0.6280 - val_loss: 0.8162 - val_accuracy: 0.6173\n",
      "Epoch 96/150\n",
      "2250/2250 [==============================] - 2s 842us/step - loss: 0.7497 - accuracy: 0.6333 - val_loss: 0.8396 - val_accuracy: 0.5920\n",
      "Epoch 97/150\n",
      "2250/2250 [==============================] - 2s 834us/step - loss: 0.7464 - accuracy: 0.6378 - val_loss: 0.8501 - val_accuracy: 0.5827\n",
      "Epoch 98/150\n",
      "2250/2250 [==============================] - 2s 833us/step - loss: 0.7526 - accuracy: 0.6258 - val_loss: 0.8309 - val_accuracy: 0.5640\n",
      "Epoch 99/150\n",
      "2250/2250 [==============================] - 2s 833us/step - loss: 0.7460 - accuracy: 0.6316 - val_loss: 0.8168 - val_accuracy: 0.6120\n",
      "Epoch 100/150\n",
      "2250/2250 [==============================] - 2s 835us/step - loss: 0.7437 - accuracy: 0.6302 - val_loss: 0.8717 - val_accuracy: 0.5507\n",
      "Epoch 101/150\n",
      "2250/2250 [==============================] - 2s 836us/step - loss: 0.7453 - accuracy: 0.6431 - val_loss: 0.8467 - val_accuracy: 0.5893\n",
      "Epoch 102/150\n",
      "2250/2250 [==============================] - 2s 834us/step - loss: 0.7448 - accuracy: 0.6222 - val_loss: 0.8662 - val_accuracy: 0.5613\n",
      "Epoch 103/150\n",
      "2250/2250 [==============================] - 2s 740us/step - loss: 0.7387 - accuracy: 0.6378 - val_loss: 0.8232 - val_accuracy: 0.5907\n",
      "Epoch 104/150\n",
      "2250/2250 [==============================] - 2s 691us/step - loss: 0.7424 - accuracy: 0.6347 - val_loss: 0.8514 - val_accuracy: 0.5587\n",
      "Epoch 105/150\n",
      "2250/2250 [==============================] - 2s 804us/step - loss: 0.7399 - accuracy: 0.6422 - val_loss: 0.8432 - val_accuracy: 0.5827\n",
      "Epoch 106/150\n",
      "2250/2250 [==============================] - 2s 798us/step - loss: 0.7417 - accuracy: 0.6311 - val_loss: 0.8649 - val_accuracy: 0.5667\n",
      "Epoch 107/150\n",
      "2250/2250 [==============================] - 2s 807us/step - loss: 0.7369 - accuracy: 0.6436 - val_loss: 0.8601 - val_accuracy: 0.5613\n",
      "Epoch 108/150\n",
      "2250/2250 [==============================] - 2s 812us/step - loss: 0.7344 - accuracy: 0.6391 - val_loss: 0.8182 - val_accuracy: 0.6147\n",
      "Epoch 109/150\n",
      "2250/2250 [==============================] - 2s 795us/step - loss: 0.7288 - accuracy: 0.6511 - val_loss: 0.8407 - val_accuracy: 0.5747\n",
      "Epoch 110/150\n",
      "2250/2250 [==============================] - 2s 803us/step - loss: 0.7344 - accuracy: 0.6360 - val_loss: 0.8305 - val_accuracy: 0.5920\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 2s 801us/step - loss: 0.7325 - accuracy: 0.6560 - val_loss: 0.8339 - val_accuracy: 0.5973\n",
      "Epoch 112/150\n",
      "2250/2250 [==============================] - 2s 818us/step - loss: 0.7318 - accuracy: 0.6427 - val_loss: 0.8353 - val_accuracy: 0.6040\n",
      "Epoch 113/150\n",
      "2250/2250 [==============================] - 2s 812us/step - loss: 0.7273 - accuracy: 0.6484 - val_loss: 0.8458 - val_accuracy: 0.5573\n",
      "Epoch 114/150\n",
      "2250/2250 [==============================] - 2s 818us/step - loss: 0.7238 - accuracy: 0.6524 - val_loss: 0.8468 - val_accuracy: 0.5973\n",
      "Epoch 115/150\n",
      "2250/2250 [==============================] - 2s 821us/step - loss: 0.7264 - accuracy: 0.6498 - val_loss: 0.9982 - val_accuracy: 0.5133\n",
      "Epoch 116/150\n",
      "2250/2250 [==============================] - 2s 841us/step - loss: 0.7307 - accuracy: 0.6458 - val_loss: 0.8331 - val_accuracy: 0.5853\n",
      "Epoch 117/150\n",
      "2250/2250 [==============================] - 2s 831us/step - loss: 0.7249 - accuracy: 0.6542 - val_loss: 0.8349 - val_accuracy: 0.5973\n",
      "Epoch 118/150\n",
      "2250/2250 [==============================] - 2s 862us/step - loss: 0.7212 - accuracy: 0.6520 - val_loss: 0.8520 - val_accuracy: 0.5907\n",
      "Epoch 119/150\n",
      "2250/2250 [==============================] - 2s 820us/step - loss: 0.7195 - accuracy: 0.6573 - val_loss: 0.8241 - val_accuracy: 0.5960\n",
      "Epoch 120/150\n",
      "2250/2250 [==============================] - 2s 820us/step - loss: 0.7208 - accuracy: 0.6507 - val_loss: 0.8412 - val_accuracy: 0.5773\n",
      "Epoch 121/150\n",
      "2250/2250 [==============================] - 2s 816us/step - loss: 0.7219 - accuracy: 0.6467 - val_loss: 0.8870 - val_accuracy: 0.5467\n",
      "Epoch 122/150\n",
      "2250/2250 [==============================] - 2s 744us/step - loss: 0.7203 - accuracy: 0.6391 - val_loss: 0.8359 - val_accuracy: 0.5880\n",
      "Epoch 123/150\n",
      "2250/2250 [==============================] - 2s 694us/step - loss: 0.7219 - accuracy: 0.6524 - val_loss: 0.9006 - val_accuracy: 0.5413\n",
      "Epoch 124/150\n",
      "2250/2250 [==============================] - 2s 761us/step - loss: 0.7195 - accuracy: 0.6564 - val_loss: 0.8536 - val_accuracy: 0.5747\n",
      "Epoch 125/150\n",
      "2250/2250 [==============================] - 2s 809us/step - loss: 0.7177 - accuracy: 0.6556 - val_loss: 0.9205 - val_accuracy: 0.5427\n",
      "Epoch 126/150\n",
      "2250/2250 [==============================] - 2s 820us/step - loss: 0.7144 - accuracy: 0.6613 - val_loss: 0.8625 - val_accuracy: 0.5853\n",
      "Epoch 127/150\n",
      "2250/2250 [==============================] - 2s 827us/step - loss: 0.7174 - accuracy: 0.6560 - val_loss: 0.9021 - val_accuracy: 0.5453\n",
      "Epoch 128/150\n",
      "2250/2250 [==============================] - 2s 811us/step - loss: 0.7097 - accuracy: 0.6631 - val_loss: 0.8508 - val_accuracy: 0.5840\n",
      "Epoch 129/150\n",
      "2250/2250 [==============================] - 2s 822us/step - loss: 0.7066 - accuracy: 0.6613 - val_loss: 0.8566 - val_accuracy: 0.5600\n",
      "Epoch 130/150\n",
      "2250/2250 [==============================] - 2s 837us/step - loss: 0.7087 - accuracy: 0.6573 - val_loss: 0.9027 - val_accuracy: 0.5427\n",
      "Epoch 131/150\n",
      "2250/2250 [==============================] - 2s 866us/step - loss: 0.7053 - accuracy: 0.6662 - val_loss: 0.8344 - val_accuracy: 0.5973\n",
      "Epoch 132/150\n",
      "2250/2250 [==============================] - 2s 854us/step - loss: 0.7126 - accuracy: 0.6560 - val_loss: 0.8765 - val_accuracy: 0.5667\n",
      "Epoch 133/150\n",
      "2250/2250 [==============================] - 2s 852us/step - loss: 0.7078 - accuracy: 0.6533 - val_loss: 0.8846 - val_accuracy: 0.5560\n",
      "Epoch 134/150\n",
      "2250/2250 [==============================] - 2s 802us/step - loss: 0.6987 - accuracy: 0.6742 - val_loss: 0.9193 - val_accuracy: 0.5427\n",
      "Epoch 135/150\n",
      "2250/2250 [==============================] - 2s 835us/step - loss: 0.7002 - accuracy: 0.6640 - val_loss: 0.8293 - val_accuracy: 0.6013\n",
      "Epoch 136/150\n",
      "2250/2250 [==============================] - 2s 834us/step - loss: 0.7042 - accuracy: 0.6600 - val_loss: 0.8281 - val_accuracy: 0.6067\n",
      "Epoch 137/150\n",
      "2250/2250 [==============================] - 2s 800us/step - loss: 0.7029 - accuracy: 0.6640 - val_loss: 0.8375 - val_accuracy: 0.5827\n",
      "Epoch 138/150\n",
      "2250/2250 [==============================] - 2s 803us/step - loss: 0.6939 - accuracy: 0.6649 - val_loss: 0.8620 - val_accuracy: 0.5733\n",
      "Epoch 139/150\n",
      "2250/2250 [==============================] - 2s 806us/step - loss: 0.6971 - accuracy: 0.6640 - val_loss: 0.9479 - val_accuracy: 0.5347\n",
      "Epoch 140/150\n",
      "2250/2250 [==============================] - 2s 802us/step - loss: 0.6955 - accuracy: 0.6569 - val_loss: 0.8460 - val_accuracy: 0.5773\n",
      "Epoch 141/150\n",
      "2250/2250 [==============================] - 2s 798us/step - loss: 0.6933 - accuracy: 0.6707 - val_loss: 0.8399 - val_accuracy: 0.6000\n",
      "Epoch 142/150\n",
      "2250/2250 [==============================] - 2s 803us/step - loss: 0.6971 - accuracy: 0.6613 - val_loss: 0.8867 - val_accuracy: 0.5627\n",
      "Epoch 143/150\n",
      "2250/2250 [==============================] - 2s 816us/step - loss: 0.6942 - accuracy: 0.6662 - val_loss: 0.9084 - val_accuracy: 0.5533\n",
      "Epoch 144/150\n",
      "2250/2250 [==============================] - 2s 841us/step - loss: 0.6865 - accuracy: 0.6800 - val_loss: 0.8921 - val_accuracy: 0.5907\n",
      "Epoch 145/150\n",
      "2250/2250 [==============================] - 2s 827us/step - loss: 0.6945 - accuracy: 0.6622 - val_loss: 0.9019 - val_accuracy: 0.5907\n",
      "Epoch 146/150\n",
      "2250/2250 [==============================] - 2s 824us/step - loss: 0.6888 - accuracy: 0.6720 - val_loss: 0.8430 - val_accuracy: 0.5893\n",
      "Epoch 147/150\n",
      "2250/2250 [==============================] - 2s 853us/step - loss: 0.6842 - accuracy: 0.6760 - val_loss: 0.9421 - val_accuracy: 0.5307\n",
      "Epoch 148/150\n",
      "2250/2250 [==============================] - 2s 811us/step - loss: 0.6868 - accuracy: 0.6653 - val_loss: 0.8659 - val_accuracy: 0.5827\n",
      "Epoch 149/150\n",
      "2250/2250 [==============================] - 2s 800us/step - loss: 0.6849 - accuracy: 0.6738 - val_loss: 0.8583 - val_accuracy: 0.5880\n",
      "Epoch 150/150\n",
      "2250/2250 [==============================] - 2s 804us/step - loss: 0.6826 - accuracy: 0.6689 - val_loss: 0.8754 - val_accuracy: 0.5693\n"
     ]
    }
   ],
   "source": [
    "# train the neural network\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=EPOCHS, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.59      0.31      0.41       236\n",
      "        dogs       0.43      0.70      0.53       236\n",
      "       panda       0.80      0.67      0.73       278\n",
      "\n",
      "    accuracy                           0.57       750\n",
      "   macro avg       0.60      0.56      0.56       750\n",
      "weighted avg       0.61      0.57      0.57       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"output/plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing network and label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(\"saved_models/simple_nn.model\")\n",
    "f = open(\"output/simple_nn_lb.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
