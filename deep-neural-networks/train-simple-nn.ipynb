{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images('animals')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, resize the image to be 32x32 pixels (ignoring\n",
    "    # aspect ratio), flatten the image into 32x32x3=3072 pixel image\n",
    "    # into a list, and store the image in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (32, 32)).flatten()\n",
    "    data.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors (for 2-class, binary\n",
    "# classification you should use Keras' to_categorical function\n",
    "# instead as the scikit-learn's LabelBinarizer will not return a\n",
    "# vector)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the 3072-1024-512-3 architecture using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate and # of epochs to train for\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    "\n",
    "# compile the model using SGD as our optimizer and categorical\n",
    "# cross-entropy loss (you'll want to use binary_crossentropy\n",
    "# for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cats', 'dogs', 'panda'], dtype='<U5')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2250 samples, validate on 750 samples\n",
      "Epoch 1/75\n",
      "2250/2250 [==============================] - 2s 948us/step - loss: 1.1071 - accuracy: 0.3422 - val_loss: 1.0793 - val_accuracy: 0.3733\n",
      "Epoch 2/75\n",
      "2250/2250 [==============================] - 2s 978us/step - loss: 1.0849 - accuracy: 0.3960 - val_loss: 1.0983 - val_accuracy: 0.3147\n",
      "Epoch 3/75\n",
      "2250/2250 [==============================] - 2s 971us/step - loss: 1.0689 - accuracy: 0.4173 - val_loss: 1.0457 - val_accuracy: 0.4653\n",
      "Epoch 4/75\n",
      "2250/2250 [==============================] - 2s 962us/step - loss: 1.0513 - accuracy: 0.4276 - val_loss: 1.0831 - val_accuracy: 0.3160\n",
      "Epoch 5/75\n",
      "2250/2250 [==============================] - 2s 963us/step - loss: 1.0364 - accuracy: 0.4649 - val_loss: 1.0896 - val_accuracy: 0.3627\n",
      "Epoch 6/75\n",
      "2250/2250 [==============================] - 2s 965us/step - loss: 1.0237 - accuracy: 0.4956 - val_loss: 1.0263 - val_accuracy: 0.4827\n",
      "Epoch 7/75\n",
      "2250/2250 [==============================] - 2s 969us/step - loss: 1.0132 - accuracy: 0.4769 - val_loss: 1.0056 - val_accuracy: 0.4840\n",
      "Epoch 8/75\n",
      "2250/2250 [==============================] - 2s 1ms/step - loss: 0.9944 - accuracy: 0.5089 - val_loss: 0.9730 - val_accuracy: 0.5307\n",
      "Epoch 9/75\n",
      "2250/2250 [==============================] - 2s 936us/step - loss: 0.9826 - accuracy: 0.5036 - val_loss: 0.9610 - val_accuracy: 0.5253\n",
      "Epoch 10/75\n",
      "2250/2250 [==============================] - 2s 927us/step - loss: 0.9692 - accuracy: 0.5067 - val_loss: 0.9963 - val_accuracy: 0.4747\n",
      "Epoch 11/75\n",
      "2250/2250 [==============================] - 2s 925us/step - loss: 0.9589 - accuracy: 0.5044 - val_loss: 1.0092 - val_accuracy: 0.4373\n",
      "Epoch 12/75\n",
      "2250/2250 [==============================] - 2s 925us/step - loss: 0.9435 - accuracy: 0.5164 - val_loss: 0.9450 - val_accuracy: 0.5453\n",
      "Epoch 13/75\n",
      "2250/2250 [==============================] - 2s 927us/step - loss: 0.9312 - accuracy: 0.5293 - val_loss: 0.9289 - val_accuracy: 0.5560\n",
      "Epoch 14/75\n",
      "2250/2250 [==============================] - 2s 926us/step - loss: 0.9239 - accuracy: 0.5347 - val_loss: 0.9115 - val_accuracy: 0.5520\n",
      "Epoch 15/75\n",
      "2250/2250 [==============================] - 2s 925us/step - loss: 0.9138 - accuracy: 0.5489 - val_loss: 0.8988 - val_accuracy: 0.5453\n",
      "Epoch 16/75\n",
      "2250/2250 [==============================] - 2s 938us/step - loss: 0.9125 - accuracy: 0.5182 - val_loss: 0.9004 - val_accuracy: 0.5267\n",
      "Epoch 17/75\n",
      "2250/2250 [==============================] - 2s 936us/step - loss: 0.8965 - accuracy: 0.5547 - val_loss: 0.9018 - val_accuracy: 0.5493\n",
      "Epoch 18/75\n",
      "2250/2250 [==============================] - 2s 930us/step - loss: 0.8959 - accuracy: 0.5369 - val_loss: 0.9322 - val_accuracy: 0.5067\n",
      "Epoch 19/75\n",
      "2250/2250 [==============================] - 2s 939us/step - loss: 0.8859 - accuracy: 0.5356 - val_loss: 0.9133 - val_accuracy: 0.5240\n",
      "Epoch 20/75\n",
      "2250/2250 [==============================] - 2s 923us/step - loss: 0.8810 - accuracy: 0.5404 - val_loss: 0.8681 - val_accuracy: 0.5533\n",
      "Epoch 21/75\n",
      "2250/2250 [==============================] - 2s 933us/step - loss: 0.8792 - accuracy: 0.5471 - val_loss: 0.9656 - val_accuracy: 0.4760\n",
      "Epoch 22/75\n",
      "2250/2250 [==============================] - 2s 927us/step - loss: 0.8730 - accuracy: 0.5516 - val_loss: 0.8581 - val_accuracy: 0.6000\n",
      "Epoch 23/75\n",
      "2250/2250 [==============================] - 2s 929us/step - loss: 0.8664 - accuracy: 0.5622 - val_loss: 0.8907 - val_accuracy: 0.5253\n",
      "Epoch 24/75\n",
      "2250/2250 [==============================] - 2s 937us/step - loss: 0.8635 - accuracy: 0.5604 - val_loss: 0.9173 - val_accuracy: 0.5427\n",
      "Epoch 25/75\n",
      "2250/2250 [==============================] - 2s 936us/step - loss: 0.8623 - accuracy: 0.5560 - val_loss: 0.8603 - val_accuracy: 0.5520\n",
      "Epoch 26/75\n",
      "2250/2250 [==============================] - 2s 964us/step - loss: 0.8549 - accuracy: 0.5582 - val_loss: 0.8534 - val_accuracy: 0.5760\n",
      "Epoch 27/75\n",
      "2250/2250 [==============================] - 2s 940us/step - loss: 0.8529 - accuracy: 0.5556 - val_loss: 0.9903 - val_accuracy: 0.4667\n",
      "Epoch 28/75\n",
      "2250/2250 [==============================] - 2s 933us/step - loss: 0.8524 - accuracy: 0.5618 - val_loss: 0.8840 - val_accuracy: 0.5347\n",
      "Epoch 29/75\n",
      "2250/2250 [==============================] - 2s 935us/step - loss: 0.8434 - accuracy: 0.5644 - val_loss: 0.9184 - val_accuracy: 0.5160\n",
      "Epoch 30/75\n",
      "2250/2250 [==============================] - 2s 930us/step - loss: 0.8469 - accuracy: 0.5533 - val_loss: 0.8389 - val_accuracy: 0.5960\n",
      "Epoch 31/75\n",
      "2250/2250 [==============================] - 2s 943us/step - loss: 0.8409 - accuracy: 0.5693 - val_loss: 0.8854 - val_accuracy: 0.5307\n",
      "Epoch 32/75\n",
      "2250/2250 [==============================] - 2s 938us/step - loss: 0.8421 - accuracy: 0.5556 - val_loss: 0.8474 - val_accuracy: 0.5693\n",
      "Epoch 33/75\n",
      "2250/2250 [==============================] - 2s 974us/step - loss: 0.8345 - accuracy: 0.5742 - val_loss: 0.8683 - val_accuracy: 0.5493\n",
      "Epoch 34/75\n",
      "2250/2250 [==============================] - 2s 938us/step - loss: 0.8345 - accuracy: 0.5613 - val_loss: 0.8619 - val_accuracy: 0.5427\n",
      "Epoch 35/75\n",
      "2250/2250 [==============================] - 2s 950us/step - loss: 0.8322 - accuracy: 0.5782 - val_loss: 0.8397 - val_accuracy: 0.5920\n",
      "Epoch 36/75\n",
      "2250/2250 [==============================] - 2s 950us/step - loss: 0.8271 - accuracy: 0.5751 - val_loss: 0.9269 - val_accuracy: 0.5133\n",
      "Epoch 37/75\n",
      "2250/2250 [==============================] - 2s 936us/step - loss: 0.8238 - accuracy: 0.5844 - val_loss: 0.8293 - val_accuracy: 0.6040\n",
      "Epoch 38/75\n",
      "2250/2250 [==============================] - 2s 941us/step - loss: 0.8239 - accuracy: 0.5778 - val_loss: 0.9065 - val_accuracy: 0.5587\n",
      "Epoch 39/75\n",
      "2250/2250 [==============================] - 2s 954us/step - loss: 0.8246 - accuracy: 0.5840 - val_loss: 0.8415 - val_accuracy: 0.5587\n",
      "Epoch 40/75\n",
      "2250/2250 [==============================] - 2s 943us/step - loss: 0.8203 - accuracy: 0.5733 - val_loss: 0.8580 - val_accuracy: 0.5467\n",
      "Epoch 41/75\n",
      "2250/2250 [==============================] - 2s 952us/step - loss: 0.8222 - accuracy: 0.5782 - val_loss: 0.8448 - val_accuracy: 0.5573\n",
      "Epoch 42/75\n",
      "2250/2250 [==============================] - 2s 957us/step - loss: 0.8221 - accuracy: 0.5844 - val_loss: 0.8865 - val_accuracy: 0.5267\n",
      "Epoch 43/75\n",
      "2250/2250 [==============================] - 2s 941us/step - loss: 0.8174 - accuracy: 0.5827 - val_loss: 0.8967 - val_accuracy: 0.5280\n",
      "Epoch 44/75\n",
      "2250/2250 [==============================] - 2s 962us/step - loss: 0.8171 - accuracy: 0.5849 - val_loss: 0.8325 - val_accuracy: 0.5813\n",
      "Epoch 45/75\n",
      "2250/2250 [==============================] - 2s 953us/step - loss: 0.8119 - accuracy: 0.5889 - val_loss: 0.8275 - val_accuracy: 0.5987\n",
      "Epoch 46/75\n",
      "2250/2250 [==============================] - 2s 959us/step - loss: 0.8146 - accuracy: 0.5916 - val_loss: 0.8273 - val_accuracy: 0.5867\n",
      "Epoch 47/75\n",
      "2250/2250 [==============================] - 2s 969us/step - loss: 0.8085 - accuracy: 0.5933 - val_loss: 0.8300 - val_accuracy: 0.5987\n",
      "Epoch 48/75\n",
      "2250/2250 [==============================] - 2s 954us/step - loss: 0.8047 - accuracy: 0.5876 - val_loss: 0.9290 - val_accuracy: 0.5280\n",
      "Epoch 49/75\n",
      "2250/2250 [==============================] - 2s 949us/step - loss: 0.8129 - accuracy: 0.5796 - val_loss: 0.9102 - val_accuracy: 0.5293\n",
      "Epoch 50/75\n",
      "2250/2250 [==============================] - 2s 959us/step - loss: 0.8079 - accuracy: 0.5796 - val_loss: 0.9021 - val_accuracy: 0.5640\n",
      "Epoch 51/75\n",
      "2250/2250 [==============================] - 2s 952us/step - loss: 0.8096 - accuracy: 0.5938 - val_loss: 0.8348 - val_accuracy: 0.5693\n",
      "Epoch 52/75\n",
      "2250/2250 [==============================] - 2s 868us/step - loss: 0.8037 - accuracy: 0.5880 - val_loss: 0.8308 - val_accuracy: 0.5987\n",
      "Epoch 53/75\n",
      "2250/2250 [==============================] - 2s 808us/step - loss: 0.8020 - accuracy: 0.5911 - val_loss: 0.8429 - val_accuracy: 0.5773\n",
      "Epoch 54/75\n",
      "2250/2250 [==============================] - 2s 816us/step - loss: 0.8013 - accuracy: 0.5929 - val_loss: 0.8300 - val_accuracy: 0.5800\n",
      "Epoch 55/75\n",
      "2250/2250 [==============================] - 2s 815us/step - loss: 0.7971 - accuracy: 0.5964 - val_loss: 0.8377 - val_accuracy: 0.5653\n",
      "Epoch 56/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 2s 827us/step - loss: 0.7988 - accuracy: 0.5951 - val_loss: 0.8972 - val_accuracy: 0.5547\n",
      "Epoch 57/75\n",
      "2250/2250 [==============================] - 2s 858us/step - loss: 0.7982 - accuracy: 0.5964 - val_loss: 0.8237 - val_accuracy: 0.6053\n",
      "Epoch 58/75\n",
      "2250/2250 [==============================] - 2s 827us/step - loss: 0.7967 - accuracy: 0.5893 - val_loss: 0.9118 - val_accuracy: 0.5213\n",
      "Epoch 59/75\n",
      "2250/2250 [==============================] - 2s 830us/step - loss: 0.7963 - accuracy: 0.5880 - val_loss: 0.8262 - val_accuracy: 0.5787\n",
      "Epoch 60/75\n",
      "2250/2250 [==============================] - 2s 819us/step - loss: 0.7926 - accuracy: 0.5987 - val_loss: 0.8620 - val_accuracy: 0.5933\n",
      "Epoch 61/75\n",
      "2250/2250 [==============================] - 2s 819us/step - loss: 0.7879 - accuracy: 0.6182 - val_loss: 0.8845 - val_accuracy: 0.5800\n",
      "Epoch 62/75\n",
      "2250/2250 [==============================] - 2s 918us/step - loss: 0.7918 - accuracy: 0.6018 - val_loss: 0.8618 - val_accuracy: 0.5440\n",
      "Epoch 63/75\n",
      "2250/2250 [==============================] - 2s 967us/step - loss: 0.7881 - accuracy: 0.6044 - val_loss: 0.9799 - val_accuracy: 0.5147\n",
      "Epoch 64/75\n",
      "2250/2250 [==============================] - 2s 966us/step - loss: 0.7895 - accuracy: 0.6107 - val_loss: 0.8516 - val_accuracy: 0.5640\n",
      "Epoch 65/75\n",
      "2250/2250 [==============================] - 2s 964us/step - loss: 0.7880 - accuracy: 0.6040 - val_loss: 0.8200 - val_accuracy: 0.6000\n",
      "Epoch 66/75\n",
      "2250/2250 [==============================] - 2s 972us/step - loss: 0.7859 - accuracy: 0.6049 - val_loss: 0.8651 - val_accuracy: 0.5733\n",
      "Epoch 67/75\n",
      "2250/2250 [==============================] - 2s 963us/step - loss: 0.7850 - accuracy: 0.6098 - val_loss: 0.8912 - val_accuracy: 0.5307\n",
      "Epoch 68/75\n",
      "2250/2250 [==============================] - 2s 973us/step - loss: 0.7835 - accuracy: 0.5969 - val_loss: 0.8210 - val_accuracy: 0.6120\n",
      "Epoch 69/75\n",
      "2250/2250 [==============================] - 2s 968us/step - loss: 0.7788 - accuracy: 0.6107 - val_loss: 0.8250 - val_accuracy: 0.6013\n",
      "Epoch 70/75\n",
      "2250/2250 [==============================] - 2s 927us/step - loss: 0.7816 - accuracy: 0.5938 - val_loss: 0.8362 - val_accuracy: 0.5733\n",
      "Epoch 71/75\n",
      "2250/2250 [==============================] - 2s 970us/step - loss: 0.7769 - accuracy: 0.6089 - val_loss: 0.8544 - val_accuracy: 0.5360\n",
      "Epoch 72/75\n",
      "2250/2250 [==============================] - 2s 950us/step - loss: 0.7794 - accuracy: 0.6058 - val_loss: 0.8392 - val_accuracy: 0.5800\n",
      "Epoch 73/75\n",
      "2250/2250 [==============================] - 2s 936us/step - loss: 0.7737 - accuracy: 0.6111 - val_loss: 0.8481 - val_accuracy: 0.5467\n",
      "Epoch 74/75\n",
      "2250/2250 [==============================] - 2s 975us/step - loss: 0.7805 - accuracy: 0.6160 - val_loss: 0.8515 - val_accuracy: 0.5587\n",
      "Epoch 75/75\n",
      "2250/2250 [==============================] - 2s 985us/step - loss: 0.7707 - accuracy: 0.6138 - val_loss: 0.8300 - val_accuracy: 0.5800\n"
     ]
    }
   ],
   "source": [
    "# train the neural network\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=EPOCHS, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.68      0.19      0.30       236\n",
      "        dogs       0.45      0.67      0.54       236\n",
      "       panda       0.70      0.83      0.76       278\n",
      "\n",
      "    accuracy                           0.58       750\n",
      "   macro avg       0.61      0.57      0.53       750\n",
      "weighted avg       0.61      0.58      0.55       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"output/plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing network and label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(\"saved_models/simple_nn.model\")\n",
    "f = open(\"output/simple_nn_lb.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
