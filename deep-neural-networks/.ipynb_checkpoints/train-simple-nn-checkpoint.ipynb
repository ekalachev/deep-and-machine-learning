{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images('animals')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, resize the image to be 32x32 pixels (ignoring\n",
    "    # aspect ratio), flatten the image into 32x32x3=3072 pixel image\n",
    "    # into a list, and store the image in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (32, 32)).flatten()\n",
    "    data.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors (for 2-class, binary\n",
    "# classification you should use Keras' to_categorical function\n",
    "# instead as the scikit-learn's LabelBinarizer will not return a\n",
    "# vector)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the 3072-1024-512-3 architecture using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate and # of epochs to train for\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 150\n",
    "\n",
    "# compile the model using SGD as our optimizer and categorical\n",
    "# cross-entropy loss (you'll want to use binary_crossentropy\n",
    "# for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cats', 'dogs', 'panda'], dtype='<U5')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2250 samples, validate on 750 samples\n",
      "Epoch 1/75\n",
      "2250/2250 [==============================] - 2s 844us/step - loss: 1.1016 - accuracy: 0.3556 - val_loss: 1.1035 - val_accuracy: 0.3720\n",
      "Epoch 2/75\n",
      "2250/2250 [==============================] - 2s 820us/step - loss: 1.0833 - accuracy: 0.3791 - val_loss: 1.0986 - val_accuracy: 0.3147\n",
      "Epoch 3/75\n",
      "2250/2250 [==============================] - 2s 794us/step - loss: 1.0676 - accuracy: 0.4080 - val_loss: 1.1310 - val_accuracy: 0.3147\n",
      "Epoch 4/75\n",
      "2250/2250 [==============================] - 2s 846us/step - loss: 1.0543 - accuracy: 0.4400 - val_loss: 1.0409 - val_accuracy: 0.5240\n",
      "Epoch 5/75\n",
      "2250/2250 [==============================] - 2s 889us/step - loss: 1.0416 - accuracy: 0.4613 - val_loss: 1.0348 - val_accuracy: 0.5280\n",
      "Epoch 6/75\n",
      "2250/2250 [==============================] - 2s 875us/step - loss: 1.0249 - accuracy: 0.4800 - val_loss: 1.0082 - val_accuracy: 0.5187\n",
      "Epoch 7/75\n",
      "2250/2250 [==============================] - 2s 858us/step - loss: 1.0090 - accuracy: 0.4916 - val_loss: 1.0144 - val_accuracy: 0.5267\n",
      "Epoch 8/75\n",
      "2250/2250 [==============================] - 2s 871us/step - loss: 0.9930 - accuracy: 0.5098 - val_loss: 0.9741 - val_accuracy: 0.5213\n",
      "Epoch 9/75\n",
      "2250/2250 [==============================] - 2s 894us/step - loss: 0.9836 - accuracy: 0.5124 - val_loss: 0.9957 - val_accuracy: 0.5040\n",
      "Epoch 10/75\n",
      "2250/2250 [==============================] - 2s 840us/step - loss: 0.9671 - accuracy: 0.5138 - val_loss: 0.9476 - val_accuracy: 0.5720\n",
      "Epoch 11/75\n",
      "2250/2250 [==============================] - 2s 823us/step - loss: 0.9501 - accuracy: 0.5276 - val_loss: 0.9398 - val_accuracy: 0.5280\n",
      "Epoch 12/75\n",
      "2250/2250 [==============================] - 2s 830us/step - loss: 0.9494 - accuracy: 0.5191 - val_loss: 0.9540 - val_accuracy: 0.5213\n",
      "Epoch 13/75\n",
      "2250/2250 [==============================] - 2s 827us/step - loss: 0.9394 - accuracy: 0.5089 - val_loss: 0.9167 - val_accuracy: 0.5560\n",
      "Epoch 14/75\n",
      "2250/2250 [==============================] - 2s 808us/step - loss: 0.9247 - accuracy: 0.5391 - val_loss: 0.9177 - val_accuracy: 0.5200\n",
      "Epoch 15/75\n",
      "2250/2250 [==============================] - 2s 820us/step - loss: 0.9187 - accuracy: 0.5262 - val_loss: 0.9032 - val_accuracy: 0.5480\n",
      "Epoch 16/75\n",
      "2250/2250 [==============================] - 2s 809us/step - loss: 0.9080 - accuracy: 0.5311 - val_loss: 0.8984 - val_accuracy: 0.5267\n",
      "Epoch 17/75\n",
      "2250/2250 [==============================] - 2s 869us/step - loss: 0.9015 - accuracy: 0.5373 - val_loss: 0.8816 - val_accuracy: 0.5813\n",
      "Epoch 18/75\n",
      "2250/2250 [==============================] - 2s 971us/step - loss: 0.8942 - accuracy: 0.5413 - val_loss: 0.8773 - val_accuracy: 0.5653\n",
      "Epoch 19/75\n",
      "2250/2250 [==============================] - 2s 975us/step - loss: 0.8872 - accuracy: 0.5409 - val_loss: 0.8762 - val_accuracy: 0.5693\n",
      "Epoch 20/75\n",
      "2250/2250 [==============================] - 2s 914us/step - loss: 0.8798 - accuracy: 0.5489 - val_loss: 0.8871 - val_accuracy: 0.5253\n",
      "Epoch 21/75\n",
      "2250/2250 [==============================] - 2s 872us/step - loss: 0.8781 - accuracy: 0.5453 - val_loss: 0.8910 - val_accuracy: 0.5493\n",
      "Epoch 22/75\n",
      "2250/2250 [==============================] - 2s 922us/step - loss: 0.8711 - accuracy: 0.5493 - val_loss: 0.9059 - val_accuracy: 0.5147\n",
      "Epoch 23/75\n",
      "2250/2250 [==============================] - 2s 856us/step - loss: 0.8702 - accuracy: 0.5467 - val_loss: 0.8545 - val_accuracy: 0.5987\n",
      "Epoch 24/75\n",
      "2250/2250 [==============================] - 2s 873us/step - loss: 0.8666 - accuracy: 0.5573 - val_loss: 0.8552 - val_accuracy: 0.5893\n",
      "Epoch 25/75\n",
      "2250/2250 [==============================] - 2s 982us/step - loss: 0.8596 - accuracy: 0.5524 - val_loss: 0.9114 - val_accuracy: 0.5160\n",
      "Epoch 26/75\n",
      "2250/2250 [==============================] - 2s 972us/step - loss: 0.8570 - accuracy: 0.5600 - val_loss: 0.8493 - val_accuracy: 0.5640\n",
      "Epoch 27/75\n",
      "2250/2250 [==============================] - 2s 936us/step - loss: 0.8582 - accuracy: 0.5422 - val_loss: 0.8807 - val_accuracy: 0.5280\n",
      "Epoch 28/75\n",
      "2250/2250 [==============================] - 2s 880us/step - loss: 0.8521 - accuracy: 0.5729 - val_loss: 0.8537 - val_accuracy: 0.5453\n",
      "Epoch 29/75\n",
      "2250/2250 [==============================] - 2s 815us/step - loss: 0.8488 - accuracy: 0.5587 - val_loss: 0.8569 - val_accuracy: 0.5960\n",
      "Epoch 30/75\n",
      "2250/2250 [==============================] - 2s 927us/step - loss: 0.8438 - accuracy: 0.5667 - val_loss: 0.8699 - val_accuracy: 0.5600\n",
      "Epoch 31/75\n",
      "2250/2250 [==============================] - 2s 914us/step - loss: 0.8419 - accuracy: 0.5564 - val_loss: 0.8475 - val_accuracy: 0.5667\n",
      "Epoch 32/75\n",
      "2250/2250 [==============================] - 2s 926us/step - loss: 0.8438 - accuracy: 0.5564 - val_loss: 0.8767 - val_accuracy: 0.5467\n",
      "Epoch 33/75\n",
      "2250/2250 [==============================] - 2s 931us/step - loss: 0.8381 - accuracy: 0.5622 - val_loss: 0.9010 - val_accuracy: 0.5373\n",
      "Epoch 34/75\n",
      "2250/2250 [==============================] - 2s 942us/step - loss: 0.8338 - accuracy: 0.5769 - val_loss: 0.8715 - val_accuracy: 0.5947\n",
      "Epoch 35/75\n",
      "2250/2250 [==============================] - 2s 942us/step - loss: 0.8388 - accuracy: 0.5533 - val_loss: 0.8400 - val_accuracy: 0.6027\n",
      "Epoch 36/75\n",
      "2250/2250 [==============================] - 2s 948us/step - loss: 0.8312 - accuracy: 0.5676 - val_loss: 0.8494 - val_accuracy: 0.5640\n",
      "Epoch 37/75\n",
      "2250/2250 [==============================] - 2s 942us/step - loss: 0.8333 - accuracy: 0.5680 - val_loss: 0.8307 - val_accuracy: 0.6000\n",
      "Epoch 38/75\n",
      "2250/2250 [==============================] - 2s 798us/step - loss: 0.8249 - accuracy: 0.5764 - val_loss: 0.8901 - val_accuracy: 0.5360\n",
      "Epoch 39/75\n",
      "2250/2250 [==============================] - 2s 833us/step - loss: 0.8230 - accuracy: 0.5791 - val_loss: 0.8544 - val_accuracy: 0.5587\n",
      "Epoch 40/75\n",
      "2250/2250 [==============================] - 2s 861us/step - loss: 0.8214 - accuracy: 0.5742 - val_loss: 0.8293 - val_accuracy: 0.6080\n",
      "Epoch 41/75\n",
      "2250/2250 [==============================] - 2s 748us/step - loss: 0.8203 - accuracy: 0.5844 - val_loss: 0.8711 - val_accuracy: 0.5867\n",
      "Epoch 42/75\n",
      "2250/2250 [==============================] - 2s 887us/step - loss: 0.8209 - accuracy: 0.5844 - val_loss: 0.8377 - val_accuracy: 0.5893\n",
      "Epoch 43/75\n",
      "2250/2250 [==============================] - 2s 883us/step - loss: 0.8210 - accuracy: 0.5796 - val_loss: 0.8849 - val_accuracy: 0.5413\n",
      "Epoch 44/75\n",
      "2250/2250 [==============================] - 2s 866us/step - loss: 0.8194 - accuracy: 0.5747 - val_loss: 0.8450 - val_accuracy: 0.5667\n",
      "Epoch 45/75\n",
      "2250/2250 [==============================] - 2s 855us/step - loss: 0.8197 - accuracy: 0.5818 - val_loss: 0.8406 - val_accuracy: 0.5613\n",
      "Epoch 46/75\n",
      "2250/2250 [==============================] - 2s 923us/step - loss: 0.8103 - accuracy: 0.5902 - val_loss: 0.8849 - val_accuracy: 0.5307\n",
      "Epoch 47/75\n",
      "2250/2250 [==============================] - 2s 1000us/step - loss: 0.8156 - accuracy: 0.5778 - val_loss: 0.8561 - val_accuracy: 0.5573\n",
      "Epoch 48/75\n",
      "2250/2250 [==============================] - 2s 979us/step - loss: 0.8094 - accuracy: 0.5920 - val_loss: 0.8653 - val_accuracy: 0.5480\n",
      "Epoch 49/75\n",
      "2250/2250 [==============================] - 2s 1ms/step - loss: 0.8086 - accuracy: 0.5996 - val_loss: 0.8372 - val_accuracy: 0.5720\n",
      "Epoch 50/75\n",
      "2250/2250 [==============================] - 2s 994us/step - loss: 0.8083 - accuracy: 0.5760 - val_loss: 0.8305 - val_accuracy: 0.6000\n",
      "Epoch 51/75\n",
      "2250/2250 [==============================] - 2s 937us/step - loss: 0.8118 - accuracy: 0.5836 - val_loss: 0.8779 - val_accuracy: 0.5440\n",
      "Epoch 52/75\n",
      "2250/2250 [==============================] - 2s 977us/step - loss: 0.8074 - accuracy: 0.5849 - val_loss: 0.8509 - val_accuracy: 0.5560\n",
      "Epoch 53/75\n",
      "2250/2250 [==============================] - 2s 949us/step - loss: 0.8054 - accuracy: 0.5871 - val_loss: 0.8404 - val_accuracy: 0.5720\n",
      "Epoch 54/75\n",
      "2250/2250 [==============================] - 2s 910us/step - loss: 0.8030 - accuracy: 0.5924 - val_loss: 0.8414 - val_accuracy: 0.5907\n",
      "Epoch 55/75\n",
      "2250/2250 [==============================] - 2s 871us/step - loss: 0.8045 - accuracy: 0.5898 - val_loss: 0.8204 - val_accuracy: 0.5960\n",
      "Epoch 56/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 2s 1ms/step - loss: 0.8028 - accuracy: 0.5800 - val_loss: 0.8240 - val_accuracy: 0.5947\n",
      "Epoch 57/75\n",
      "2250/2250 [==============================] - 2s 979us/step - loss: 0.7975 - accuracy: 0.5907 - val_loss: 0.9103 - val_accuracy: 0.5267\n",
      "Epoch 58/75\n",
      "2250/2250 [==============================] - 2s 985us/step - loss: 0.7978 - accuracy: 0.5956 - val_loss: 0.9063 - val_accuracy: 0.5293\n",
      "Epoch 59/75\n",
      "2250/2250 [==============================] - 2s 858us/step - loss: 0.7970 - accuracy: 0.5924 - val_loss: 0.8416 - val_accuracy: 0.5840\n",
      "Epoch 60/75\n",
      "2250/2250 [==============================] - 2s 865us/step - loss: 0.8002 - accuracy: 0.5942 - val_loss: 0.8225 - val_accuracy: 0.5960\n",
      "Epoch 61/75\n",
      "2250/2250 [==============================] - 2s 848us/step - loss: 0.7896 - accuracy: 0.6053 - val_loss: 0.8187 - val_accuracy: 0.6027\n",
      "Epoch 62/75\n",
      "2250/2250 [==============================] - 2s 849us/step - loss: 0.7921 - accuracy: 0.5929 - val_loss: 0.8588 - val_accuracy: 0.5493\n",
      "Epoch 63/75\n",
      "2250/2250 [==============================] - 2s 864us/step - loss: 0.7885 - accuracy: 0.6098 - val_loss: 0.8663 - val_accuracy: 0.5307\n",
      "Epoch 64/75\n",
      "2250/2250 [==============================] - 2s 866us/step - loss: 0.7902 - accuracy: 0.6053 - val_loss: 0.8703 - val_accuracy: 0.5547\n",
      "Epoch 65/75\n",
      "2250/2250 [==============================] - 2s 879us/step - loss: 0.7871 - accuracy: 0.6071 - val_loss: 0.8463 - val_accuracy: 0.5600\n",
      "Epoch 66/75\n",
      "2250/2250 [==============================] - 2s 878us/step - loss: 0.7902 - accuracy: 0.5942 - val_loss: 0.8487 - val_accuracy: 0.5627\n",
      "Epoch 67/75\n",
      "2250/2250 [==============================] - 2s 866us/step - loss: 0.7854 - accuracy: 0.5911 - val_loss: 0.8529 - val_accuracy: 0.5347\n",
      "Epoch 68/75\n",
      "2250/2250 [==============================] - 2s 824us/step - loss: 0.7834 - accuracy: 0.6071 - val_loss: 0.8340 - val_accuracy: 0.5720\n",
      "Epoch 69/75\n",
      "2250/2250 [==============================] - 2s 822us/step - loss: 0.7821 - accuracy: 0.6018 - val_loss: 0.8433 - val_accuracy: 0.5933\n",
      "Epoch 70/75\n",
      "2250/2250 [==============================] - 2s 785us/step - loss: 0.7845 - accuracy: 0.5969 - val_loss: 0.8349 - val_accuracy: 0.5973\n",
      "Epoch 71/75\n",
      "2250/2250 [==============================] - 2s 811us/step - loss: 0.7788 - accuracy: 0.6160 - val_loss: 0.8178 - val_accuracy: 0.6093\n",
      "Epoch 72/75\n",
      "2250/2250 [==============================] - 2s 814us/step - loss: 0.7813 - accuracy: 0.6062 - val_loss: 0.8674 - val_accuracy: 0.5560\n",
      "Epoch 73/75\n",
      "2250/2250 [==============================] - 2s 809us/step - loss: 0.7800 - accuracy: 0.6111 - val_loss: 0.8209 - val_accuracy: 0.6053\n",
      "Epoch 74/75\n",
      "2250/2250 [==============================] - 2s 807us/step - loss: 0.7753 - accuracy: 0.6142 - val_loss: 0.8441 - val_accuracy: 0.5947\n",
      "Epoch 75/75\n",
      "2250/2250 [==============================] - 2s 807us/step - loss: 0.7756 - accuracy: 0.6080 - val_loss: 0.8795 - val_accuracy: 0.5320\n"
     ]
    }
   ],
   "source": [
    "# train the neural network\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=EPOCHS, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       1.00      0.02      0.04       236\n",
      "        dogs       0.40      0.84      0.55       236\n",
      "       panda       0.77      0.70      0.73       278\n",
      "\n",
      "    accuracy                           0.53       750\n",
      "   macro avg       0.73      0.52      0.44       750\n",
      "weighted avg       0.73      0.53      0.46       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"output/plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing network and label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(\"saved_models/simple_nn.model\")\n",
    "f = open(\"output/simple_nn_lb.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
